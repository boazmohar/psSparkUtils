language: python

python:
  - "2.7"
  - "3.5"
  - "3.6"

env:
  - JDK=openjdk8

dist: trusty

before_script:
  - jdk_switcher use $JDK

sudo: false

install:
  - wget -c http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh
  - bash Miniconda-latest-Linux-x86_64.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  - conda info -a
  - conda create --yes -q -n test python=$TRAVIS_PYTHON_VERSION pip pytest numpy scipy
  - source activate test
  - pip install -r requirements-dev.txt
  - wget https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz
  - tar -xzf spark-2.2.0-bin-hadoop2.7.tgz

script:
  - export SPARK_HOME=`pwd`/spark-2.2.0-bin-hadoop2.7
  - export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH
  - export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10.6-src.zip:$PYTHONPATH
  - py.test -s -v --cov=./pySparkUtils

after_success:
  - coveralls
